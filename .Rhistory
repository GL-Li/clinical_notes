str_remove_all("(\n|\t|\r)")
sample_text
transcription <- sample_text %>%
str_extract("(?=Sample Type).+(?=NOTE)")
transcription
sample_url <- "https://www.mtsamples.com/site/pages/sample.asp?Type=3-Allergy%20/%20Immunology&Sample=386-Allergic%20Rhinitis"
sample_page <- read_html(sample_url)
# category in transcribes
category <- sample_page %>%
html_nodes(css = "b") %>%
html_text() %>%
str_extract("[A-Z]{3,}") %>%
.[!is.na(.)] %>%
setdiff("NOTE")
sample_text <- sample_page %>%
html_node(xpath = '//*[@id="sampletext"]') %>%
html_text() %>%
str_remove_all("(\n|\t|\r)")
# extract everything between "Medical Specialty: " and "Sample Name: "
sample_type <- str_extract(sample_text, "(?<=Medical Specialty:).+(?=Sample Name:)") %>%
str_trim() %>% str_squish()
sample_name <- str_extract(sample_text, "(?<=Sample Name:).+(?=\r\n)") %>%
str_trim() %>% str_squish()
sample_text
sample_name <- str_extract(sample_text, "(?<=Sample Name:).+(?=    )") %>%
str_trim() %>% str_squish()
sample_name <- str_extract(sample_text, "(?<=Sample Name:).+(?=\s\s\s\s)") %>%
str_trim() %>% str_squish()
sample_name <- str_extract(sample_text, "(?<=Sample Name:).+(?=\s\s\s\s)") %>%
str_trim() %>% str_squish()
sample_text <- sample_page %>%
html_node(xpath = '//*[@id="sampletext"]') %>%
html_text()
sample_text
# extract everything between "Medical Specialty: " and "Sample Name: "
sample_type <- str_extract(sample_text, "(?<=Medical Specialty:).+(?=Sample Name:)") %>%
str_trim() %>% str_squish()
sample_name <- str_extract(sample_text, "(?<=Sample Name:).+(?=\r\n)") %>%
str_trim() %>% str_squish()
transcription <- sample_text %>%
str_remove_all("(\n|\t|\r)") %>%
str_extract("(?=Sample Type).+(?=NOTE)")
transcription
sample_text
library(data.table)
library(magrittr)
library(stringr)
dt <- fread("~/data/health-care-data/medical-transcriptions-kaggle/mtsamples.csv",
header = TRUE) %>%
.[, V1 := NULL]
names(dt)
View(dt)
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
use_condaenv()
use_python("/home/gl/anaconda3/bin/python")
remove.packages("reticulate", lib="~/R/x86_64-pc-linux-gnu-library/3.6")
install.packages("reticulate")
install.packages("reticulate")
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
Sys.which("python")
use_python("/home/gl/anaconda3/bin/python")
?use_condaenv
use_condaenv("/home/gl/anaconda3/bin/python")
use_condaenv("/home/gl/anaconda3/bin/conda")
use_condaenv()
library(reticulate)
py_install("pandas")
py_install("matplotlib")
x
py$x
plot(py$x, py$y)
aaa = seq(0, 10, 0.1)
bbb <- (aaa - 50)^2
py_install("scikit-learn")
aaa <- seq(0, 100, 0.1)
bbb <- (aaa - 50)^2
library(data.table)
library(ggplot2)
iris <- setDT(data(iris))
iris <- data(iris)
iris
iris <- data("iris")
data("iris")
iris <- data("iris") %>%
setDT()
library(magrittr)
iris <- data("iris") %>%
setDT()
names(iris)
as.dataframe(data("iris"))
as.data.frame(data("iris"))
iris <- as.data.frame(data("iris")) %>%
setDT()
iris <- data("iris")
data("iris")
names(iris) <- c("sepal_width", "sepal_length", "petal_width", "petal_length", "species")
head(iris)
ggplot(iris, aes(sepal_length, sepal_width, color = species)) +
geom_point()
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
library(ggplot2)
data("iris")
names(iris) <- c("sepal_length", "sepal_width", "petal_length", "petal_width", "species")
ggplot(iris, aes(sepal_length, sepal_width, color = species)) +
geom_point()
X = iris[, 1:4]
y = iris[, 5]
iris$pred <- py$pred
iris
ggplot(iris, aes(sepal_length, sepal_width, color=pred)) +
geom_point()
iris$pred <- as.factor(py$pred)
ggplot(iris, aes(sepal_length, sepal_width, color=pred)) +
geom_point()
ggplot(iris, aes(sepal_length, sepal_width, color = species)) +
geom_point()
library(data.table)
library(magrittr)
library(stringr)
library(ggplot2)
mt <- fread("mtsample_scraped.csv", header = TRUE)
# headers used in transcription ===============================================
# all headers
headers <- mt$mt_headers %>%
str_split(", ") %>%
unlist() %>%
.[!. == ""]
# count of each headers
header_count <- sort(table(headers), decreasing = TRUE)
header_top <- header_count[1:100]
ggplot() +
geom_col(aes(x = factor(names(header_top), levels = names(header_top)),
y = as.integer(header_top))) +
coord_flip()
header_top <- header_count[1:50]
ggplot() +
geom_col(aes(x = factor(names(header_top), levels = names(header_top)),
y = as.integer(header_top))) +
coord_flip()
headers
header_count
# header count distribution
ggplot() + geom_bar(aes(header_count))
# header count distribution
ggplot() +
geom_bar(aes(header_count)) +
xlim(0, 100)
header_top
install.packages("wordcloud")
library(wordcloud)
wordcloud(names(header_count), header_count)
wordcloud(names(header_count), header_count, max.words = 200)
warnings()
mt$mt_headers
# headers used in transcription ===============================================
# all headers in individual word
headers <- mt$mt_headers %>%
str_remove_all(",") %>%
str_split(" ") %>%
unlist() %>%
.[!. == ""]
headers
# count of each headers
header_count <- sort(table(headers), decreasing = TRUE)
# header count distribution
ggplot() +
geom_bar(aes(header_count)) +
xlim(0, 100)
header_top <- header_count[1:50]
wordcloud(names(header_count), header_count, max.words = 200)
wordcloud(names(header_count), header_count)
header_top
# headers used in transcription ===============================================
# all headers in individual word
headers <- mt$mt_headers %>%
str_split(", ") %>%
unlist() %>%
.[!. == ""]
# count of each headers
header_count <- sort(table(headers), decreasing = TRUE)
header_top <- header_count[1:50]
ggplot() +
geom_col(aes(x = factor(names(header_top), levels = names(header_top)),
y = as.integer(header_top))) +
coord_flip()
names(header_count[1:100])
# headers used in transcription ===============================================
# all headers in individual word
headers <- mt$mt_headers %>%
str_split(", ") %>%
unlist() %>%
.[!. == ""]
headers
# count of each headers
header_count <- sort(table(headers), decreasing = TRUE)
# group the same headers but in different names ===============================
names(header_count)
# group the same headers but in different names ===============================
tail(names(header_count), 100)
install.packages("RColorBrewer")
install.packages("RColorBrewer")
library(RColorBrewer)
wordcloud(names(header_count), header_count)
library(data.table)
library(magrittr)
library(stringr)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
wordcloud(names(header_count), header_count)
wordcloud(words = names(header_count), freq = header_count, min.freq = 10,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
names(header_count)
?wordcloud
wordcloud(words = names(header_count), freq = header_count,
scale = c(2, 0.5), min.freq = 10,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
warnings()
wordcloud(words = names(header_count), freq = header_count,
scale = c(1, 0.1), min.freq = 10,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = names(header_count), freq = header_count,
scale = c(1, 0.1), min.freq = 10,
max.words=2000, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = names(header_count), freq = header_count,
scale = c(1.5, 0.1), min.freq = 10,
max.words=2000, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = names(header_count), freq = header_count,
scale = c(1.3, 0.1), min.freq = 10,
max.words=2000, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = names(header_count), freq = header_count,
scale = c(1.3, 0.1), min.freq = 1,
max.words=2000, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = names(header_count), freq = header_count,
scale = c(1.3, 0.1), min.freq = 3,
max.words=2000, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = names(header_count), freq = header_count,
scale = c(1.3, 0.1), min.freq = 3,
max.words=2000, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = names(header_count), freq = header_count,
scale = c(1.3, 0.1), min.freq = 5,
max.words=2000, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = names(header_count), freq = header_count,
scale = c(1, 0.1), min.freq = 5,
max.words=2000, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = names(header_count), freq = header_count,
scale = c(1, 0.1), min.freq = 1,
max.words=2000, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
warnings(())
warnings()
wordcloud(words = names(header_count), freq = header_count,
scale = c(1, 0.1), min.freq = 3,
max.words=2000, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = names(header_count),
freq = header_count,
scale = c(1, 0.1),
min.freq = 3,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = names(header_count),
freq = header_count,
scale = c(1, 0.1),
min.freq = 10,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = names(header_count),
freq = header_count,
scale = c(1.5, 0.1),
min.freq = 10,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = names(header_count),
freq = header_count,
scale = c(1.5, 0.3),
min.freq = 10,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = names(header_count),
freq = header_count,
scale = c(1.5, 0.3),
min.freq = 10,
rot.per = 0.2,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = names(header_count),
freq = header_count,
scale = c(1.5, 0.35),
min.freq = 10,
rot.per = 0.2,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = names(header_count),
freq = header_count,
scale = c(1.5, 0.3),
min.freq = 10,
rot.per = 0.2,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
set.seed(1234)
wordcloud(words = names(header_count),
freq = header_count,
scale = c(1.5, 0.3),
min.freq = 10,
rot.per = 0.2,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = names(header_count),
freq = header_count,
scale = c(1.5, 0.2),
min.freq = 5,
rot.per = 0.2,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
wordcloud(words = names(header_count),
freq = header_count,
scale = c(1.5, 0.2),
min.freq = 5,
rot.per = 0.2,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
set.seed(1234)
wordcloud(words = names(header_count),
freq = header_count,
scale = c(1.5, 0.2),
min.freq = 5,
rot.per = 0.2,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
library(shiny)
library(data.table)
library(magrittr)
library(stringr)
mt <- fread("mtsample_scraped.csv", header = TRUE)
mt
names(mt)
mt <- fread("mtsample_scraped.csv", header = TRUE) %>%
.[, .(sample_type, note = medical_transcription)]
mt
library(DT)
data.table(mt, options = list(searchHighlight=TRUE))
library(DT)
data.table(mt, options = list(searchHighlight=TRUE))
runApp('shiny-apps')
runApp('shiny-apps')
getwd()
setwd("~/Dropbox/work-with-health-data/medical-transcription/shiny-apps")
runApp()
shiny::runApp('shiny-apps')
runApp('shiny-apps')
library(DT)
library(data.table)
library(magrittr)
mt <- fread("../mtsample_scraped.csv", header = TRUE) %>%
.[, .(sample_type, note = medical_transcription)]
mt <- fread("../../mtsample_scraped.csv", header = TRUE) %>%
.[, .(sample_type, note = medical_transcription)]
data.table(mt, options = list(searchHighlight=TRUE))
data.table(mt, options = list(searchHighlight=TRUE))
data.table(mt)
data.table(mt)
?datatable
getwd()
data("iris")
library(DT)
datatable(iris)
mt = read.csv("mtsample_scraped.csv", stringsAsFactors = F)
mt
names(mt)
mt <- mt[, c(1, 4)]
View(mt)
datatable(mt[1:10],)
datatable(mt[1:10,])
datatable(mt)
library(data.table)
aa = fread("mtsample_scraped.csv")
names(aa)
bb = aa[, .(sample_type, medical_transcription)]
datatable(aa[1:10])
datatable(bb[1:10])
mt <- fread("../../mtsample_scraped.csv") %>%
.[, .(sample_type, note = medical_transcription)]
datatable(mt)
shiny::runApp('shiny-apps')
datatable(mt[1:10])
datatable(mt[1:100])
runApp('shiny-apps')
?library(shiny)
library(shiny)
?tableOutput
names(mt)
mt <- fread("../mtsample_scraped.csv", header = TRUE) %>%
.[, .(sample_type, note = medical_transcription)]
getwd()
mt <- fread("mtsample_scraped.csv") %>%
.[, .(sample_type, note = medical_transcription)]
runApp('shiny-apps')
runApp('shiny-apps')
runApp('shiny-apps')
datatable(mt[1:100])
runApp('shiny-apps')
if (interactive()) {
# pass a callback function to DataTables using I()
shinyApp(
ui = fluidPage(
fluidRow(
column(12,
dataTableOutput('table')
)
)
),
server = function(input, output) {
output$table <- renderDataTable(iris,
options = list(
pageLength = 5,
initComplete = I("function(settings, json) {alert('Done.');}")
)
)
}
)
}
library(shiny)
runApp('shiny-apps')
runApp('shiny-apps')
runApp('shiny-apps')
runApp('shiny-apps')
runApp('shiny-apps')
runApp('shiny-apps')
runApp('shiny-apps')
shiny::runApp('shiny-apps')
runApp('shiny-apps')
runApp('shiny-apps')
runApp('shiny-apps')
?fluidRow
runApp('shiny-apps')
runApp('shiny-apps')
runApp('shiny-apps')
runApp('shiny-apps')
runApp('shiny-apps')
runApp('shiny-apps')
runApp('shiny-apps')
?renderDataTable
DT::datatable(mt)
DT::datatable(mt, options = list(searchHighlight=T, search=list(caseInsensitive=F)))
mt <- fread("../mtsample_scraped.csv")
library(data.table)
library(magrittr)
library(stringr)
mt <- fread("../mtsample_scraped.csv")
mt <- fread("../mtsample_scraped.csv")
runApp('shiny-apps')
runApp('shiny-apps')
runApp('shiny-apps')
runApp('shiny-apps')
?datatable
runApp('shiny-apps')
runApp('shiny-apps')
runApp('shiny-apps')
runApp('shiny-apps')
runApp('shiny-apps')
shiny::runApp('shiny-apps')
library(data.table)
library(magrittr)
library(stringr)
mt <- fread("../mtsample_scraped.csv")
library(data.table)
library(magrittr)
library(stringr)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
mt <- fread("mtsample_scraped.csv", header = TRUE)
unique(mt$sample_type)
# medical notes ===============================================================
notes = mt[sample_type %in% c("Gastroenterology", "Neurology"),
.(sample_type, medical_transcription)]
# medical notes ===============================================================
# select 100 from each of Gastroenterology and Neurology for machine learning
notes = mt[sample_type %in% c("Gastroenterology", "Neurology"),
.(sample_type, medical_transcription)] %>%
.[, .SD[1:100], by = sample_type]
View(notes)
fwrite(notes, file="selected_notes.csv", row.names = FALSE)
# medical notes ===============================================================
# select 100 from each of Gastroenterology and Neurology for machine learning
notes = mt[sample_type %in% c("Gastroenterology", "Neurology"),
.(sample_type, medical_transcription)]
fwrite(notes, file="selected_notes.csv", row.names = FALSE)
# medical notes ===============================================================
# select 100 from each of Gastroenterology and Neurology for machine learning
notes = mt[sample_type %in% c("Gastroenterology", "Neurology"),
.(sample_type, medical_transcription)] %>%
.[, .SD[1:100], by = sample_type]
fwrite(notes, file="selected_notes.csv", row.names = FALSE)
shiny::runApp('shiny-apps')
