)
cols <- c("specialty", "note")
set.seed(1234)
dat <- read_notes(
"data/mtsamples_multi_class.csv",
duplicate_rm = T,
specialties = specialties,
cols_keep = cols,
id = TRUE,
y_label = TRUE
)
tfidf <- tfidf_tm(dat$note)
y <- as.factor(dat$y)  # svm requires y to be factor
X <- tfidf
set.seed(11111)
in_train <- caret::createDataPartition(y, p = 0.7, list = FALSE)
X_train <- X[in_train,]
X_test <- X[-in_train,]
y_train <- y[in_train]
y_test <- y[-in_train]
mdl <- svm(X_train, y_train)
y_pred <- predict(mdl, X_test)
classes_x <- c(
"Gastroenterology", "Obstetrics\nGynecology",  "Cardiovascular\nPulmonary",
"Neurology", "Urology", "Orthopedic"
)
classes_y <- c(
"Gastro-\nenterology", "Obstetrics\nGynecology",  "Cardiovascular\nPulmonary",
"Neurology", "Urology", "Orthopedic"
)
ggplot_multiclass_svm_tfidf_recall <- plot_confusion_matrix(y_test, y_pred, classes_x, classes_y, type = "recall")
ggplot_multiclass_svm_tfidf_precision <- plot_confusion_matrix(y_test, y_pred, classes_x, classes_y, type = "precision")
caret::confusionMatrix(y_test, y_pred)
?caret::confusionMatrix
caret::confusionMatrix(y_pred, y_test)
caret::confusionMatrix(y_pred, y_test) -> a
names(a)
a$overall
a$overall$Accuracy
a$overall[1]
accuracy_svm_tfidf <- caret::confusionMatrix(y_pred, y_test) %>%
.$overall[1]
a["overall"]
accuracy_svm_tfidf <- caret::confusionMatrix(y_pred, y_test) %>%
.["overall"][1]
ModelMetrics::recall(y_test, y_pred)
table(y_test, y_pred)
accuracy <- function(y_true, y_pred){
# Calculate classification accuracy
#
# Arguments:
#   y_true: integer, true class
#   y_pred: numeric, predicted probability
# Return:
#  numeric
tb <- table(y_true, y_pred)
acc <- sum(diag(tb)) / length(y_test_class)
}
accuracy_svm_tfidf <- accuracy(y_test, y_pred)
accuracy <- function(y_true, y_pred){
# Calculate classification accuracy
#
# Arguments:
#   y_true: integer, true class
#   y_pred: numeric, predicted probability
# Return:
#  numeric
tb <- table(y_true, y_pred)
acc <- sum(diag(tb)) / length(y_true)
}
accuracy_svm_tfidf <- accuracy(y_test, y_pred)
# one model pca ================================================================
# visually pick 25 as the best n_pca to train model
# results: exellent recall and precision
X <- prcomp(tfidf)$x[, 1:25]
set.seed(11111)
in_train <- caret::createDataPartition(y, p = 0.7, list = FALSE)
X_train <- X[in_train,]
X_test <- X[-in_train,]
y_train <- y[in_train]
y_test <- y[-in_train]
mdl <- svm(X_train, y_train)
y_pred <- predict(mdl, X_test)
classes_x <- c(
"Gastroenterology", "Obstetrics\nGynecology",  "Cardiovascular\nPulmonary",
"Neurology", "Urology", "Orthopedic"
)
classes_y <- c(
"Gastro-\nenterology", "Obstetrics\nGynecology",  "Cardiovascular\nPulmonary",
"Neurology", "Urology", "Orthopedic"
)
ggplot_multiclass_svm_pca_recall <- plot_confusion_matrix(y_test, y_pred, classes_x, classes_y)
ggplot_multiclass_svm_pca_precision <- plot_confusion_matrix(y_test, y_pred, classes_x, classes_y, type = "precision")
accuracy_svm_pca <- accuracy(y_test, y_pred)
# save for shiny ===============================================================
save(ggplot_multiclass_svm_pca_recall, ggplot_multiclass_svm_pca_precision,
ggplot_multiclass_svm_tfidf_recall, ggplot_multiclass_svm_tfidf_precision,
accuracy_svm_tfidf, accuracy_svm_pca,
file = "shiny-apps/RData/ggplot_multiclass_svm.RData")
library(xgboost)
source("utilities.R")
# prepare data =================================================================
specialties <- c(
"Gastroenterology", "Obstetrics / Gynecology",  "Cardiovascular / Pulmonary",
"Neurology", "Urology", "Orthopedic"
)
cols <- c("specialty", "note")
set.seed(1234)
dat <- read_notes(
"data/mtsamples_multi_class.csv",
duplicate_rm = TRUE,
specialties = specialties,
cols_keep = cols,
id = TRUE,
y_label = TRUE
)
tfidf <- tfidf_tm(dat$note)
y <- dat$y
n_class <- length(unique(y))
# one model: tfidf =============================================================
X <- tfidf
set.seed(11111)
in_train <- caret::createDataPartition(y, p = 0.7, list = FALSE)
X_train <- X[in_train,]
X_test <- X[-in_train,]
y_train <- y[in_train]
y_test <- y[-in_train]
param <- list(objective = "multi:softmax",
num_class = n_class,
eval_metric = "merror",
max_depth = 5,
eta = 0.4
)
xgb <- xgboost(data = X_train,
label = y_train,
params = param,
nthread = 3,
nrounds = 25)
y_pred <- predict(xgb, X_test)
table(y_test, y_pred)
classes_x <- c(
"Gastroenterology", "Obstetrics\nGynecology",  "Cardiovascular\nPulmonary",
"Neurology", "Urology", "Orthopedic"
)
classes_y <- c(
"Gastro-\nenterology", "Obstetrics\nGynecology",  "Cardiovascular\nPulmonary",
"Neurology", "Urology", "Orthopedic"
)
ggplot_multiclass_xgb_tfidf_recall<- plot_confusion_matrix(y_test, y_pred, classes_x, classes_y)
ggplot_multiclass_xgb_tfidf_precision <- plot_confusion_matrix(y_test, y_pred, classes_x, classes_y, type = "precision")
accuracy_xgb_tfidf <- accuracy(y_test, y_pred)
# one model: pca   =============================================================
X <- prcomp(tfidf)$x[, 1:25]
set.seed(11111)
in_train <- caret::createDataPartition(y, p = 0.7, list = FALSE)
X_train <- X[in_train,]
X_test <- X[-in_train,]
y_train <- y[in_train]
y_test <- y[-in_train]
param <- list(objective = "multi:softmax",
num_class = n_class,
eval_metric = "merror",
max_depth = 5,
eta = 0.4
)
xgb <- xgboost(data = X_train,
label = y_train,
params = param,
nthread = 3,
nrounds = 25)
y_pred <- predict(xgb, X_test)
table(y_test, y_pred)
classes_x <- c(
"Gastroenterology", "Obstetrics\nGynecology",  "Cardiovascular\nPulmonary",
"Neurology", "Urology", "Orthopedic"
)
classes_y <- c(
"Gastro-\nenterology", "Obstetrics\nGynecology",  "Cardiovascular\nPulmonary",
"Neurology", "Urology", "Orthopedic"
)
ggplot_multiclass_xgb_pca_recall <- plot_confusion_matrix(y_test, y_pred, classes_x, classes_y)
ggplot_multiclass_xgb_pca_precision <- plot_confusion_matrix(y_test, y_pred, classes_x, classes_y, type = "precision")
accuracy_xgb_pca <- accuracy(y_test, y_pred)
# save for shiny
save(ggplot_multiclass_xgb_pca_recall, ggplot_multiclass_xgb_pca_precision,
ggplot_multiclass_xgb_tfidf_recall, ggplot_multiclass_xgb_tfidf_precision,
accuracy_xgb_tfidf, accuracy_xgb_pca,
file = "shiny-apps/RData/ggplot_multiclass_xgb.RData")
library(tensorflow)
library(keras)
source("utilities.R")
# prepare data =================================================================
specialties <- c(
"Gastroenterology", "Obstetrics / Gynecology",  "Cardiovascular / Pulmonary",
"Neurology", "Urology", "Orthopedic"
)
cols <- c("specialty", "note")
dat <- read_notes(
"data/mtsamples_multi_class.csv",
duplicate_rm = TRUE,
specialties = specialties,
cols_keep = cols,
id = TRUE,
y_label = TRUE
)
notes <- dat$note
# one model tfidf ==============================================================
# initialize tokenizer specifing maximum words
tk <- text_tokenizer(num_words = 3000)
# update tk in place with a vector or list of documents
fit_text_tokenizer(tk, notes)
# convert the documents into a matrix of tfidf
X <- texts_to_matrix(tk, notes, mode = "tfidf")
# normalize the matrix so that length of each row vector is 1
X <- X / sqrt(rowSums(X * X))
# for multiclass, y should be converted to a matrix
y_class <- dat$y
n_class <- length(unique(y_class))
y <- to_categorical(y_class, n_class)
# split X and y into train and test
set.seed(11111)
in_train <- caret::createDataPartition(y_class, p = 0.7, list = FALSE)
X_train <- X[in_train,]
y_train <- y[in_train,]
X_test <- X[-in_train,]
y_test <- y[-in_train]
y_test_class <- y_class[-in_train]
model <- keras_model_sequential() %>%
# input layer
layer_dense(32, input_shape = dim(X_train)[2], activation = "relu") %>%
layer_dropout(0.2) %>%
# second layer
layer_dense(units = 16, activation = "relu") %>%
layer_dropout(0.2) %>%
# output layer
layer_dense(n_class, activation = "softmax")
# compile, fit, and evaluate model in place
compile(model,
loss = "categorical_crossentropy",
optimizer = "adam",
metrics = "accuracy"
)
fit(model,
x = X_train, y = y_train,
epochs = 20,
batch_size = 32,
validation_split = 0.3,
verbose = 3
)
y_pred <- predict(model, X_test)
y_pred_class <- predict_classes(model, X_test)
table(y_test_class, y_pred_class)
classes_x <- c(
"Gastroenterology", "Obstetrics\nGynecology",  "Cardiovascular\nPulmonary",
"Neurology", "Urology", "Orthopedic"
)
classes_y <- c(
"Gastro-\nenterology", "Obstetrics\nGynecology",  "Cardiovascular\nPulmonary",
"Neurology", "Urology", "Orthopedic"
)
ggplot_multiclass_nn_tfidf_recall <- plot_confusion_matrix(y_test_class, y_pred_class, classes_x, classes_y)
ggplot_multiclass_nn_tfidf_precision <- plot_confusion_matrix(y_test_class, y_pred_class, classes_x, classes_y, type = "precision")
accuracy_nn_tfidf <- accuracy(y_test, y_pred)
accuracy_nn_tfidf <- accuracy(y_test, y_pred_class)
accuracy_nn_tfidf <- accuracy(y_test_class, y_pred_class)
# initialize tokenizer specifing maximum words
tk <- text_tokenizer(num_words = 3000)
# update tk in place with a vector or list of documents
fit_text_tokenizer(tk, notes)
# convert the documents into a matrix of tfidf
X <- texts_to_matrix(tk, notes, mode = "tfidf")
# normalize the matrix so that length of each row vector is 1
X <- X / sqrt(rowSums(X * X))
X <- prcomp(X)$x[, 1:25]
# for multiclass, y should be converted to a matrix
y_class <- dat$y
n_class <- length(unique(y_class))
y <- to_categorical(y_class, n_class)
# split X and y into train and test
set.seed(11111)
in_train <- caret::createDataPartition(y_class, p = 0.7, list = FALSE)
X_train <- X[in_train,]
y_train <- y[in_train,]
X_test <- X[-in_train,]
y_test <- y[-in_train]
y_test_class <- y_class[-in_train]
model <- keras_model_sequential() %>%
# input layer
layer_dense(32, input_shape = dim(X_train)[2], activation = "relu") %>%
layer_dropout(0.2) %>%
# second layer
layer_dense(units = 16, activation = "relu") %>%
layer_dropout(0.2) %>%
# output layer
layer_dense(n_class, activation = "softmax")
# compile, fit, and evaluate model in place
compile(model,
loss = "categorical_crossentropy",
optimizer = "adam",
metrics = "accuracy"
)
fit(model,
x = X_train, y = y_train,
epochs = 20,
batch_size = 32,
validation_split = 0.3,
verbose = 3
)
y_pred <- predict(model, X_test)
model <- keras_model_sequential() %>%
# input layer
layer_dense(32, input_shape = dim(X_train)[2], activation = "relu") %>%
layer_dropout(0.2) %>%
# second layer
layer_dense(units = 16, activation = "relu") %>%
layer_dropout(0.2) %>%
# output layer
layer_dense(n_class, activation = "softmax")
# compile, fit, and evaluate model in place
compile(model,
loss = "categorical_crossentropy",
optimizer = "adam",
metrics = "accuracy"
)
fit(model,
x = X_train, y = y_train,
epochs = 30,
batch_size = 32,
validation_split = 0.3,
verbose = 3
)
y_pred <- predict(model, X_test)
y_pred_class <- predict_classes(model, X_test)
table(y_test_class, y_pred_class)
classes_x <- c(
"Gastroenterology", "Obstetrics\nGynecology",  "Cardiovascular\nPulmonary",
"Neurology", "Urology", "Orthopedic"
)
classes_y <- c(
"Gastro-\nenterology", "Obstetrics\nGynecology",  "Cardiovascular\nPulmonary",
"Neurology", "Urology", "Orthopedic"
)
ggplot_multiclass_nn_pca_recall <- plot_confusion_matrix(y_test_class, y_pred_class, classes_x, classes_y)
ggplot_multiclass_nn_pca_precision <- plot_confusion_matrix(y_test_class, y_pred_class, classes_x, classes_y, type = "precision")
accuracy_nn_pca <- accuracy(y_test_class, y_pred_class)
# save for shiny
save(ggplot_multiclass_nn_pca_recall, ggplot_multiclass_nn_pca_precision,
ggplot_multiclass_nn_tfidf_recall, ggplot_multiclass_nn_tfidf_precision,
accuracy_nn_tfidf, accuracy_nn_pca,
file = "shiny-apps/RData/ggplot_multiclass_nn.RData")
library(tensorflow)
library(keras)
source("utilities.R")
# prepare data =================================================================
specialties <- c(
"Gastroenterology", "Obstetrics / Gynecology",  "Cardiovascular / Pulmonary",
"Neurology", "Urology", "Orthopedic"
)
cols <- c("specialty", "note")
dat <- read_notes(
"data/mtsamples_multi_class.csv",
duplicate_rm = TRUE,
specialties = specialties,
cols_keep = cols,
id = TRUE,
y_label = TRUE
)
# one model ====================================================================
max_words = 3500
seq_length = 350
dim_emb = 120
dropout = 0.4
n_filters = 32
notes <- dat$note
tk <- text_tokenizer(num_words = max_words)
fit_text_tokenizer(tk, notes)
X <- texts_to_sequences(tk, notes)
X <- pad_sequences(X, seq_length)
y_class <- dat$y
n_class <- length(unique(y_class))
y <- to_categorical(y_class, n_class)
# split X and y into train and test
set.seed(11111)
in_train <- caret::createDataPartition(y_class, p = 0.7, list = FALSE)
X_train <- X[in_train,]
y_train <- y[in_train,]
X_test <- X[-in_train,]
y_test <- y[-in_train,]
y_test_class <- y_class[-in_train]
model <- keras_model_sequential() %>%
layer_embedding(input_dim = max_words,
output_dim = dim_emb,
input_length = seq_length) %>%
layer_dropout(dropout) %>%
layer_conv_1d(filters = n_filters,
kernel_size = 3,
#activation = "relu",
padding = "valid",
strides = 1) %>%
layer_dropout(dropout) %>%
layer_global_average_pooling_1d() %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dropout(dropout) %>%
# output layer
layer_dense(n_class, activation = "softmax")
# compile, fit, and evaluate model in place
compile(model,
loss = "categorical_crossentropy",
optimizer = "adam",
metrics = "accuracy"
)
fit(model,
x = X_train,
y = y_train,
epochs = 20,
batch_size = 32,
validation_split = 0.3,
verbose = 3
)
y_pred <- predict(model, X_test)
y_pred_class <- predict_classes(model, X_test)
table(y_test_class, y_pred_class)
classes_x <- c(
"Gastroenterology", "Obstetrics\nGynecology",  "Cardiovascular\nPulmonary",
"Neurology", "Urology", "Orthopedic"
)
classes_y <- c(
"Gastro-\nenterology", "Obstetrics\nGynecology",  "Cardiovascular\nPulmonary",
"Neurology", "Urology", "Orthopedic"
)
ggplot_multiclass_nn_embedding_recall <- plot_confusion_matrix(y_test_class, y_pred_class, classes_x, classes_y)
ggplot_multiclass_nn_embedding_precision <- plot_confusion_matrix(y_test_class, y_pred_class, classes_x, classes_y, type = "precision")
accuracy_nn_embedding <- accuracy(y_test_class, y_pred_class)
save(ggplot_multiclass_nn_embedding_recall,
ggplot_multiclass_nn_embedding_precision,
accuracy_nn_embedding,
file = "shiny-apps/RData/ggplot_multiclass_nn_embedding.RData")
# classification ===============================================================
# .. multiclass ====
load("RData/ggplot_multiclass_svm.RData")
runApp('shiny-apps')
runApp('shiny-apps')
runApp()
runApp('shiny-apps')
runApp('shiny-apps')
runApp('shiny-apps')
shiny::runApp('shiny-apps')
install.packages("wordcloud")
runApp('shiny-apps')
install.packages("dendextend")
runApp('shiny-apps')
install.packages("shinydashboard")
runApp('shiny-apps')
install.packages("DT")
runApp('shiny-apps')
install.packages("tm")
runApp('shiny-apps')
install.packages("slam")
install.packages("slam")
install.packages("slam")
install.packages("tm")
shiny::runApp('shiny-apps')
ls
ls()
runApp('shiny-apps')
runApp('shiny-apps')
runApp('shiny-apps')
runApp('shiny-apps')
runApp('shiny-apps')
runApp('shiny-apps')
runApp('shiny-apps')
runApp('shiny-apps')
shiny::runApp('shiny-apps')
library(e1071)
library(progress)
source("utilities.R")
# prepare data =================================================================
specialties <- c(
"Gastroenterology", "Obstetrics / Gynecology",  "Cardiovascular / Pulmonary",
"Neurology", "Urology", "Orthopedic"
)
cols <- c("specialty", "note")
set.seed(1234)
dat <- read_notes(
"data/mtsamples_multi_class.csv",
duplicate_rm = T,
specialties = specialties,
cols_keep = cols,
id = TRUE,
y_label = TRUE
)
tfidf <- tfidf_tm(dat$note)
y <- as.factor(dat$y)  # svm requires y to be factor
# one model pca ================================================================
# visually pick 25 as the best n_pca to train model
# results: exellent recall and precision
X <- prcomp(tfidf)$x[, 1:25]
set.seed(11111)
in_train <- caret::createDataPartition(y, p = 0.7, list = FALSE)
X_train <- X[in_train,]
X_test <- X[-in_train,]
y_train <- y[in_train]
y_test <- y[-in_train]
mdl <- svm(X_train, y_train)
y_pred <- predict(mdl, X_test)
classes_x <- c(
"Gastroenterology", "Obstetrics\nGynecology",  "Cardiovascular\nPulmonary",
"Neurology", "Urology", "Orthopedic"
)
model_svm_pca <- mdl
saveRDS(model_svm_pca, file = "shiny-apps/trained_models/model_svm_pca.rda")
install.packages("text2vec")
