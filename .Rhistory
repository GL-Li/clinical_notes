tokens <- as_tibble(df) %>%
select(id, !!col) %>%
unnest_tokens(word, !!col) %>%
anti_join(stop_words) %>%
count(id, word, sort = TRUE) %>%
# keep words with letters only
filter(str_detect(word, "^[a-z]+$"))
# number of document contains a word
n_documents <- tokens %>%
group_by(word) %>%
summarise(n_documents = n(),
n_times = sum(n))
# words only shows up one time
words_1 <- n_documents %>%
filter(n_times == 1) %>%
select(word) %>%
pull()
# remove the one-time words, which are note represenative
tokens <- tokens %>%
filter(!word %in% words_1)
# total words in a document
total_words <- tokens %>%
group_by(id) %>%
summarise(total = sum(n))
df_tfidf <- left_join(tokens, total_words) %>%
bind_tf_idf(word, id, n)
# top 10 words by term frequency in each document
top_tf <- df_tfidf %>%
arrange(desc(tf)) %>%
group_by(id) %>%
slice(1:10) %>%
select(id, word) %>%
group_by(id) %>%
summarise(top_tf = paste(word, collapse = " "))
# top 10 words by tfidf
top_tfidf <- df_tfidf %>%
arrange(desc(tf_idf)) %>%
group_by(id) %>%
slice(1:10) %>%
select(id, word) %>%
group_by(id) %>%
summarise(top_tfidf = paste(word, collapse = " "))
sum_tfidf <- df_tfidf %>%
group_by(id) %>%
summarise(sum_tfidf = round(sum(tf_idf), 3)) %>%
left_join(top_tf) %>%
left_join(top_tfidf) %>%
arrange(id) %>%
cbind(df)
return(list(tfidf = sum_tfidf, n_doc = n_documents[, c("word", "n_documents")]))
}
tfidf <- get_tfidf(notes, "medical_note")
tfidf_list <- get_tfidf(notes, "medical_note")
sum_tfidf <- tfidf_list[["tfidf"]] %>%
setkey("id")
View(sum_tfidf)
n_documents <- tfidf_list[["n_doc"]]
View(n_documents)
runApp()
runApp()
View(note_bows)
class(sum_tfidf)
sum_tfidf
names(sum_tfidf)
top_tf
top_tfidf
names(df_tfidf)
names(sum_tfidf)
sum_tfidf <- df_tfidf %>%
group_by(id) %>%
summarise(sum_tfidf = round(sum(tf_idf), 3))
names(sum_tfidf)
df
names(df)
sum_tfidf <- df_tfidf %>%
group_by(id) %>%
summarise(sum_tfidf = round(sum(tf_idf), 3)) %>%
left_join(top_tf) %>%
left_join(top_tfidf) %>%
right_join(df) %>%
arrange(id)
View(sum_tfidf)
runApp()
runApp()
ggplot(sum_tfidf, aes(sum_tfidf, color = sample_type)) + geom_boxplot()
ggplot(sum_tfidf, aes(sample_type, sum_tfidf)) + geom_boxplot()
ggplot(sum_tfidf, aes(sample_type, sum_tfidf)) + geom_boxplot() + geom_jitter(width = 0.15)
ggplot(sum_tfidf, aes(sample_type, sum_tfidf)) +
geom_boxplot() +
geom_jitter(width = 0.15) +
xlab("Sample Type") +
ylab("Sum of TFIDF") +
ggtitle("Sum of TFIDF of a Document")
runApp()
runApp()
runApp()
runApp()
class(n_documents)
names(n_documents)
runApp()
runApp()
runApp()
runApp()
?textInput
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
?renderText
runApp()
runApp()
runApp()
runApp()
runApp()
length("abd")
nchar("abc")
runApp()
runApp()
class(NULL)
runApp()
runApp()
n_documents %>% filter(word == "a a") %>% pull(n_documents)
aaa = n_documents %>% filter(word == "a a") %>% pull(n_documents)
int(aaa)
as.integer(aaa)
str(aaa)
aaa == integer(0)
aaa
is_empty(aaa)
runApp()
?is_empty
runApp()
?column
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
count = 111
#h2(str(count))
paste0("<p><font size='12'>", count, "</font>", " documents</p>")
runApp()
library(DT)
?datatable
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
source('~/Dropbox/work-with-health-data/medical-notes/shiny-apps/controllers/bow_text.R')
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
names(tokens)
df_tfidf
runApp()
runApp()
library(data.table)
library(tidyverse)
library(tidytext)
# get tf and tfidf words
notes <- fread("data/mtsample_gastroenterology_neurology.csv") %>%
# missing space after ".", for example "abscess.PROCEDURE"
.[, medical_note := str_replace_all(medical_note, "\\.", "\\. ")]
setwd("~/Dropbox/work-with-health-data/medical-notes/shiny-apps")
# get tf and tfidf words
notes <- fread("data/mtsample_gastroenterology_neurology.csv") %>%
# missing space after ".", for example "abscess.PROCEDURE"
.[, medical_note := str_replace_all(medical_note, "\\.", "\\. ")]
names(notes)
df = notes
col = "medical_note"
# count of a word in a document
tokens <- as_tibble(df) %>%
select(id, !!col) %>%
unnest_tokens(word, !!col) %>%
anti_join(stop_words) %>%
count(id, word, sort = TRUE) %>%
# keep words with letters only
filter(str_detect(word, "^[a-z]+$"))
# times of appearance of a word
n_times <- tokens %>%
group_by(word) %>%
summarise(n_times = sum(n))
# words only shows up one time
words_1 <- n_times %>%
filter(n_times == 1) %>%
select(word) %>%
pull()
# remove the one-time words, which are note represenative
tokens <- tokens %>%
filter(!word %in% words_1)
# total words in a document
total_words <- tokens %>%
group_by(id) %>%
summarise(total = sum(n))
df_tfidf <- left_join(tokens, total_words) %>%
bind_tf_idf(word, id, n)
str(df_tfidf)
# stats of a word
word_stats <- df_tfidf %>%
group_by(word) %>%
summarise(n_documents = n(),
n_times = sum(n),
avg_tf = round(mean(tf),4),
avg_tfidf = round(mean(tf_idf), 4))
View(word_stats)
shiny::runApp()
runApp()
names(word_stats)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
?icon
runApp()
runApp()
?includeCSS
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
?renderTable
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
source('~/Dropbox/work-with-health-data/medical-notes/eda_analysis.R')
runApp()
runApp()
?icon
runApp()
library(data.table)
library(tidyverse)
library(tidytext)
# define function to extract top words using term frequency and tfidf
get_tfidf <- function(df, col){
# df: dataframe containing a column of corpus
# col: string, column name of the corpus selected for tfidf
# count of a word in a document
tokens <- as_tibble(df) %>%
select(id, !!col) %>%
unnest_tokens(word, !!col) %>%
anti_join(stop_words) %>%
count(id, word, sort = TRUE) %>%
# keep words with letters only
filter(str_detect(word, "^[a-z]+$"))
# times of appearance of a word
n_times <- tokens %>%
group_by(word) %>%
summarise(n_times = sum(n))
# words only shows up one time
words_1 <- n_times %>%
filter(n_times == 1) %>%
select(word) %>%
pull()
# remove the one-time words, which are note represenative
tokens <- tokens %>%
filter(!word %in% words_1)
# total words in a document
total_words <- tokens %>%
group_by(id) %>%
summarise(total = sum(n))
df_tfidf <- left_join(tokens, total_words) %>%
bind_tf_idf(word, id, n)
# stats of a word
word_stats <- df_tfidf %>%
group_by(word) %>%
summarise(n_documents = n(),
n_times = sum(n),
avg_tf = round(mean(tf),4),
avg_tfidf = round(mean(tf_idf), 4))
# top 10 words by term frequency in each document
top_tf <- df_tfidf %>%
arrange(desc(tf)) %>%
group_by(id) %>%
slice(1:10) %>%
select(id, word) %>%
group_by(id) %>%
summarise(top_tf = paste(word, collapse = " "))
# top 10 words by tfidf
top_tfidf <- df_tfidf %>%
arrange(desc(tf_idf)) %>%
group_by(id) %>%
slice(1:10) %>%
select(id, word) %>%
group_by(id) %>%
summarise(top_tfidf = paste(word, collapse = " "))
sum_tfidf <- df_tfidf %>%
group_by(id) %>%
summarise(sum_tfidf = round(sum(tf_idf), 3)) %>%
left_join(top_tf) %>%
left_join(top_tfidf) %>%
right_join(df) %>%
arrange(id)
return(list(tfidf = sum_tfidf, word_stats = word_stats))
}
# get tf and tfidf words
notes <- fread("mtsample_gastroenterology_neurology.csv") %>%
# missing space after ".", for example "abscess.PROCEDURE"
.[, medical_note := str_replace_all(medical_note, "\\.", "\\. ")]
setwd("~/Dropbox/work-with-health-data/medical-notes/shiny-apps/preprocess_data_for_RData")
# get tf and tfidf words
notes <- fread("mtsample_gastroenterology_neurology.csv") %>%
# missing space after ".", for example "abscess.PROCEDURE"
.[, medical_note := str_replace_all(medical_note, "\\.", "\\. ")]
tfidf_list <- get_tfidf(notes, "medical_note")
sum_tfidf <- tfidf_list[["tfidf"]] %>%
setDT() %>%
setkey("id")
word_stats <- tfidf_list[["word_stats"]]
# get medical entities created by Amazon Comprehend Medical
amazon_me <- fread("data/amazon_medical_entities.csv") %>%
setkey("id") %>%
.[, amazon_me := tolower(amazon_me)]
# get medical entites created by medaCy
medacy_me <- fread("data/medacy_medical_entities.csv") %>%
setkey("id") %>%
.[, medacy_me := tolower(medacy_me)]
# combine all for shiny server
note_bows <- sum_tfidf %>%
medacy_me[.] %>%
amazon_me[.]
# get medical entities created by Amazon Comprehend Medical
amazon_me <- fread("amazon_medical_entities.csv") %>%
setkey("id") %>%
.[, amazon_me := tolower(amazon_me)]
# get medical entites created by medaCy
medacy_me <- fread("medacy_medical_entities.csv") %>%
setkey("id") %>%
.[, medacy_me := tolower(medacy_me)]
# combine all for shiny server
note_bows <- sum_tfidf %>%
medacy_me[.] %>%
amazon_me[.]
View(note_bows)
names(amazon_me)
# create data for word cloud
amazon_words <- amazon_me[, amazon_me]
# create data for word cloud
amazon_words <- amazon_me[, amazon_me] %>%
str_split(" ")
# create data for word cloud
amazon_words <- amazon_me[, amazon_me] %>%
str_split(" ", simplify = TRUE)
amazon_words
amazon_words <- amazon_me[, amazon_me]
# create data for word cloud
amazon_words <- amazon_me[, amazon_me] %>%
str_split(" ") %>%
unlist()
amazon_words
# create data for word cloud
amazon_words <- amazon_me[, amazon_me] %>%
str_split(" ") %>%
unlist() %>%
table()
amazon_words
# create data for word cloud
amazon_words <- amazon_me[, amazon_me] %>%
str_split(" ") %>%
unlist() %>%
table() %>%
sort()
amazon_words
amazon_words[1:10]
tail(amazon_words)
# create data for word cloud
amazon_words <- amazon_me[, amazon_me] %>%
str_split(" ") %>%
unlist() %>%
table()
bbb <- as.data.frame(amazon_words)
View(bbb)
# create data for word cloud
amazon_words <- amazon_me[, amazon_me] %>%
str_split(" ") %>%
unlist() %>%
table() %>%
as.data.table()
View(amazon_words)
# create data for word cloud
amazon_count <- amazon_me[, amazon_me] %>%
str_split(" ") %>%
unlist() %>%
table() %>%
as.data.table()
View(amazon_count)
# create data for word cloud
amazon_count <- amazon_me[, amazon_me] %>%
str_split(" ") %>%
unlist() %>%
table() %>%
as.data.table() %>%
set_colnames("word", "count")
# create data for word cloud
amazon_count <- amazon_me[, amazon_me] %>%
str_split(" ") %>%
unlist() %>%
table() %>%
as.data.table() %>%
set_colnames(c("word", "count"))
View(amazon_count)
# create data for word cloud
get_word_count <- function(vector_col){
count <- vector_col %>%
str_split(" ") %>%
unlist() %>%
table() %>%
as.data.table() %>%
set_colnames(c("word", "count"))
}
amazon_count <- get_word_count(amazon_me[, amazon_me])
medacy_count <- get_word_count(medacy_me[, medacy_me])
top_tf_count <- get_word_count(note_bows[, top_tf])
names(note_bows)
top_tfidf_count <- get_word_count(note_bows, top_tfidf)
top_tfidf_count <- get_word_count(note_bows[, top_tfidf])
View(top_tf_count)
View(top_tfidf_count)
?save
# save to RData ===============================================================
save(note_bows, word_stats, amazon_count, medacy_count,
top_tf_count, top_tfidf_count,
file = "../RData/saved.RData")
runApp('~/Dropbox/work-with-health-data/medical-notes/shiny-apps')
runApp()
runApp('~/Dropbox/work-with-health-data/medical-notes/shiny-apps')
class(note_bows)
col = "top_tf"
note_bows[, get(col)]
View(note_bows)
type = "Gastroenterology"
note_bows[sample_type == type, get(col)]
# get word count
get_word_count <- function(type, col){
count <- note_bows[sample_type == type, get(col)] %>%
str_split(" ") %>%
unlist() %>%
table() %>%
as.data.table() %>%
set_colnames(c("word", "count"))
}
word_count <- get_word_count(type, col)
word_count
wordcloud(words = word_count[, word],
freq = word_count[, count],
scale = c(1.5, 0.2),
min.freq = 5,
rot.per = 0.2,
random.order=FALSE,
colors=brewer.pal(8, "Dark2"))
note_bows
note_bows[, sample_type]
runApp('~/Dropbox/work-with-health-data/medical-notes/shiny-apps')
runApp('~/Dropbox/work-with-health-data/medical-notes/shiny-apps')
runApp('~/Dropbox/work-with-health-data/medical-notes/shiny-apps')
runApp('~/Dropbox/work-with-health-data/medical-notes/shiny-apps')
runApp('~/Dropbox/work-with-health-data/medical-notes/shiny-apps')
runApp('~/Dropbox/work-with-health-data/medical-notes/shiny-apps')
runApp('~/Dropbox/work-with-health-data/medical-notes/shiny-apps')
runApp('~/Dropbox/work-with-health-data/medical-notes/shiny-apps')
runApp('~/Dropbox/work-with-health-data/medical-notes/shiny-apps')
runApp('~/Dropbox/work-with-health-data/medical-notes/shiny-apps')
runApp('~/Dropbox/work-with-health-data/medical-notes/shiny-apps')
runApp('~/Dropbox/work-with-health-data/medical-notes/shiny-apps')
runApp('~/Dropbox/work-with-health-data/medical-notes/shiny-apps')
?wordcloud
runApp('~/Dropbox/work-with-health-data/medical-notes/shiny-apps')
runApp('~/Dropbox/work-with-health-data/medical-notes/shiny-apps')
runApp('~/Dropbox/work-with-health-data/medical-notes/shiny-apps')
runApp('~/Dropbox/work-with-health-data/medical-notes/shiny-apps')
runApp('~/Dropbox/work-with-health-data/medical-notes/shiny-apps')
runApp('~/Dropbox/work-with-health-data/medical-notes/shiny-apps')
runApp('~/Dropbox/work-with-health-data/medical-notes/shiny-apps')
runApp('~/Dropbox/work-with-health-data/medical-notes/shiny-apps')
runApp('~/Dropbox/work-with-health-data/medical-notes/shiny-apps')
